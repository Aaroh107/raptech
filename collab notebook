!curl fsSL https://ollama.ai/install.sh | sh
!wget -q https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz
!tar -xzf ngrok-v3-stable-linux-amd64.tgz

#first run this in one cell

from google.colab import userdata
auth_token = userdata.get('ngrok_auth_token')
!./ngrok authtoken {auth_token}
!ollama serve & ./ngrok http 11434 --host-header="localhost:11434" --domain="ngork domain name" --log stdout & sleep 5s && ollama run llama3

#then run this in 2nd cell 
